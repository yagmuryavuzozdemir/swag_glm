library(DescTools)

swag <- function(y, X, p_max, q, m = choose(floor(q*ncol(X)), 2), family = "gaussian", eval_func = AIC, seed = 123) {
  
  if(p_max > ncol(X)) stop("p_max is larger than the number of predictors")
  
  p <- ncol(X)
  index_screen <- 1:p
  
  # Initializing result storage
  criteria <- list()
  group <- list()
  selected_group <- list()
  
  
  ####################################
  # Screening Step
  ####################################
  
  crit <- rep(NA, p)
  
  for(i in seq_along(index_screen)) {
    
    # index of group of variables
    fit <- glm(y ~ X[, i], family = family)
    
    # RMSE for each models
    crit[i] = eval_func(fit)
    
  }
  
  criteria[[1]] <- crit
  group[[1]] <- seq_along(crit)
  id_screening <- selected_group[[1]] <- which(crit <= quantile(crit, q))
  
  
  ####################################
  # General Step
  ####################################
  
  # if(progress == T) {
  #   
  #   pb <- txtProgressBar(min = 2, max = p_max, initial = 2, style = 3) 
  #   
  # }
  
  for(d in 2:p_max) {
    
    id_row <- selected_group[[d - 1]] # indices of models in the prev. step with smaller error
    
    if(d == 2) {
      
      id_var <- group[[d - 1]][id_row] # group[[1]] is always a vector
      nrv <- length(id_var)
      
    } else {
      
      if(length(id_row) == 1) { # only one model selected from previous dimension
        
        id_var <- as.matrix(t(group[[d - 1]][id_row, ]))
        nrv <- nrow(id_var)
        
      } else {
        
        id_var <- group[[d - 1]][id_row,]
        nrv <- nrow(id_var)
        
      }
      
    }
    
    # build all possible models
    A <- matrix(nr = nrv*length(id_screening), nc = d)
    A[, 1:(d - 1)] <- kronecker(cbind(rep(1, length(id_screening))), id_var)
    A[, d] <- rep(id_screening, each = nrv)
    B <- unique(t(apply(A, 1, sort))) # deletes the repeated rows
    id_ndup <- which(apply(B, 1, anyDuplicated) == 0) # removes the models with same Xi
    
    if(length(id_ndup) == 1) {
      
      var_mat <- as.matrix(t(B[id_ndup, ]))
      
    } else {
      
      var_mat <- B[id_ndup, ] # all possible combinations of size d
      
    }
    
    rm(list=c("A", "B"))
    
    ##randomly selecting the models of size d
    if(nrow(var_mat) > m) {
      
      set.seed(seed + d)
      
      group[[d]] <- var_mat[sample.int(nrow(var_mat), m), ]
      
    } else {
      
      group[[d]] <- var_mat
      
    }
    
    var_mat <- group[[d]]
    
    crit <- rep(NA, nrow(var_mat))
    
    ##training
    for(i in seq_along(crit)){
      
      # index of group of variables
      fit <- glm(y ~ X[, var_mat[i,]], family = family)
      
      # RMSE for each models
      crit[i] = eval_func(fit)
      
    }
    
    criteria[[d]] <- na.omit(crit)
    selected_group[[d]] <- which(crit <= quantile(crit, probs = q, na.rm = T))
    
    #if(progress == T) setTxtProgressBar(pb, d)
    
  }
  
  #close(pb)
  
  out <- list("group" = group, "selected_group" = selected_group, "criteria" = criteria, "id_screening" = id_screening, "p_max" = p_max)
  class(out) <- "swag"
  
  return(out)
  
}

swag_network <- function(obj, mode = "undirected", weighted = F, show_net = T) {
  
  require(plyr)
  require(igraph)
  require(gdata)
  
  selected_ind <- list()
  
  selected_ind[[1]] <- obj$group[[1]][obj$selected_group[[1]]]
  
  for(i in 2:obj$p_max) {
    
    if(length(obj$selected_group[[i]]) != 1) {
      
      selected_ind[[i]] <- obj$group[[i]][as.matrix(obj$selected_group[[i]]), ]
      
    } else {
      
      selected_ind[[i]] <- t(as.matrix(obj$group[[i]][obj$selected_group[[i]], ]))
      
    }
    
  }
  
  
  models <- rbind.fill.matrix(selected_ind)
  
  #### intensity matrix
  
  selected_var <- c()
  
  for(i in 1:ncol(models)) {
    
    selected_var <- c(selected_var, models[, i])
    
  }
  
  selected_var <- sort(na.omit(unique(selected_var)))
  
  A <- matrix(0, nrow = ncol(models), ncol = ncol(models))
  intensity <- matrix(0, nrow = length(selected_var), ncol = length(selected_var))
  a <- list()
  
  for(i in 1:(length(selected_var) - 1)) {
    
    for(j in (i + 1):length(selected_var)) {
      
      for(k in 1:(ncol(models) - 1)) {
        
        a[[i]] <- which(models[, k] == selected_var[i])
        
        for(n in (k + 1):(ncol(models))) {
          
          A[k, n] <- length(which(models[a[[i]], n] == selected_var[j]))
          
        }
        
      }
      
      intensity[j, i] <- intensity[i, j] <- sum(A)
      
    }
    
  }
  
  colnames(intensity) <- obj$id_screening
  rownames(intensity) <- obj$id_screening
  
  #relation matrix for pairwise connection
  
  relation_mat = matrix(NA, nrow = choose(length(selected_var),2), ncol = 3)
  c = rep(selected_var[1],length(selected_var)-1)
  for(i in (length(selected_var)-2):1){
    a = rep(selected_var[length(selected_var)-i],i)
    c = c(c,a)
  }
  relation_mat[,1]=c
  
  bb = selected_var[-1]
  for(i in 3:length(selected_var)){
    b1 = selected_var[i:length(selected_var)]
    bb = c(bb,b1)
  }
  relation_mat[,2]=bb
  
  relation_mat[,3] = upperTriangle(intensity,byrow = T)
  
  g <- graph_from_adjacency_matrix(intensity, mode = mode, weighted = NULL)
  
  if(show_net == T) plot(g)
  
  return(list(g = g, models = models))
  
}


swag_significance_test <- function(y, X, swag_obs, net_obs, pmax, alpha, sign_level, B) {
  
  library(DescTools)
  
  # Frequency table for observed data
  frequency <- table(net_obs$models)
  variable <- swag_obs$id_screening
  freq_obs <- cbind(variable, frequency)
  freq_obs <- freq_obs[order(-freq_obs[, "frequency"]), ]
  
  # Compute observed statistics
  entropy_freq_obs <- Entropy(freq_obs)
  entropy_eigen_obs <- Entropy(eigen_centrality(net_obs$g)$vector)
  
  # Initialize vectors for null statistics
  entropy_freq_null <- numeric(B)
  entropy_eigen_null <- numeric(B)
  
  for (b in 1:B) {
    set.seed(b)
    # Generate response under null
    y_null <- sample(y, length(y), replace = TRUE) 
    
    # Run SWAG under null
    swag_null <- swag(y_null, X, p_max = pmax, q = alpha, family = "binomial")
    net_null <- swag_network(swag_null)
    net_null$g <- delete_vertices(net_null$g, V(net_null$g)[degree(net_null$g) == 0])
    
    # Frequency table under null
    frequency <- table(net_null$models)
    variable <- swag_null$id_screening
    freq_null <- cbind(variable, frequency)
    freq_null <- freq_null[order(-freq_null[, "frequency"]), ]
    
    # Compute null statistics
    entropy_freq_null[b] <- Entropy(freq_null)
    entropy_eigen_null[b] <- Entropy(eigen_centrality(net_null$g)$vector)
  }
  
  # Compute significance
  eigen_significance <- mean(entropy_eigen_null < entropy_eigen_obs) < sign_level
  freq_significance <- mean(entropy_freq_null < entropy_freq_obs) < sign_level
  
  # Return results
  return(list(
    eigenvector_centrality = ifelse(eigen_significance, "SWAG is significant by eigenvector centrality", "SWAG is not significant by eigenvector centrality"),
    frequency = ifelse(freq_significance, "SWAG is significant by frequency", "SWAG is not significant by frequency")
  ))
}

### Example

# Parameters for data generation
set.seed(1)
n <- 2000
p <- 20
Sigma <- diag(rep(1/p, p))

X <- MASS::mvrnorm(n = n, mu = rep(0, p), Sigma = Sigma)
beta = c(-10,5,6,19,70,rep(0,15))
z <- 1 + X%*%beta
pr <- 1/(1 + exp(-z))
y <- as.factor(rbinom(n, 1, pr))

swag_obs = swag(y, X, p_max=5, q = 0.7, family = "binomial")
swag_net = swag_network(swag_obs)
swag_test = swag_significance_test(y,X, swag_obs = swag_obs, net_obs = swag_net, pmax = 5, alpha = 0.7, sign_level = 0.1, B=50)
